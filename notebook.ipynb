{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactive, modular notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Used during development, doesn't contain all the information: more information on the Notion page."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One problem was reading the original given JSON files. The following function successfully reads them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fixed JSON loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Fixes a malformed JSON file containing multiple root objects and \n",
    "loads it into a Python list of dictionaries.\n",
    "This function addresses the issue of JSON files that have multiple root objects \n",
    "by wrapping them in an array\n",
    "and ensuring proper comma separation between objects. It then attempts to parse \n",
    "the fixed JSON string.\n",
    "Args:\n",
    "    file_path (str): The path to the JSON file to be fixed and loaded.\n",
    "Returns:\n",
    "    list: A list of dictionaries representing the fixed JSON objects if parsing is successful.\n",
    "    None: If there is an error in parsing the JSON, None is returned \n",
    "    and an error message is printed.\n",
    "\"\"\"\n",
    "\n",
    "import json\n",
    "import re\n",
    "\n",
    "def fix_malformed_json(file_path):\n",
    "    \"\"\"Fixes JSON with multiple root objects and loads it into Python.\"\"\"\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        json_string = file.read()\n",
    "\n",
    "    # Step 1: Wrap JSON objects in an array\n",
    "    fixed_json_string = f\"[{json_string}]\"\n",
    "\n",
    "    # Step 2: Remove newlines between objects and add commas\n",
    "    fixed_json_string = re.sub(r'}\\s*{', r'},{', fixed_json_string)\n",
    "\n",
    "    # Step 3: Parse the fixed JSON\n",
    "    try:\n",
    "        return json.loads(fixed_json_string)\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error parsing JSON: {e}\")\n",
    "        return None\n",
    "\n",
    "# Example usage\n",
    "FILE_PATH = \"data/economics.json\" # \"data/machine_learning_for_healthcare.json\"\n",
    "data = fix_malformed_json(FILE_PATH)\n",
    "\n",
    "if data:\n",
    "    print(\"Fixed JSON loaded successfully!\")\n",
    "    #print(json.dumps(data, indent=4))  # Pretty-print for inspection\n",
    "else:\n",
    "    print(\"Failed to fix and load JSON.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up the model - using Google's free Gemini 1.5 Flash model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ana\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "LLM API Script\n",
    "\n",
    "This script configures and initializes a generative AI model using the Google Generative AI library.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import google.generativeai as genai\n",
    "\n",
    "api_key = os.getenv(\"API_KEY\")\n",
    "genai.configure(api_key=api_key)\n",
    "model = genai.GenerativeModel(\"gemini-1.5-flash\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The text discusses the mechanisms for monitoring and addressing macroeconomic imbalances among EU member states, particularly through the Specific Monitoring and the Excessive Imbalance Procedure (EIP). It also examines the European Stability Mechanism's role in providing financial assistance to euro area countries facing severe financial issues. The Portuguese case is presented to illustrate economic trends and imbalances leading up to the Economic and Monetary Union (EMU).\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# Get a random index\n",
    "random_index = random.randint(1, len(data) - 1)\n",
    "\n",
    "# Get the chunk at the random index\n",
    "random_chunk = data[random_index]\n",
    "text = random_chunk['content'].get('text', 'N/A')\n",
    "summary = random_chunk['content'].get('summary', 'N/A')\n",
    "main_topic = random_chunk['content'].get('main_topic', 'N/A')\n",
    "subtopics = random_chunk['content'].get('subtopics', 'N/A')\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT = \"\"\"\n",
    "You are an AI assistant tasked with creating multiple-choice questions for learning.\n",
    "You are given a chunk of text, a brief summary of that text, the main topic it belongs to, and a subtopics.\n",
    "\n",
    "Generate a single multiple-choice question with the following properties:\n",
    "- All the needed context must be in the question itself. Students don't see the text or summary.\n",
    "- One True Answer: The correct answer must be directly supported by the information in the text and/or summary provided. Give an explanation for why this option is correct.\n",
    "-Three Plausible Distractors: \n",
    "    - The incorrect answer options must be related to the main topic or subtopic.\n",
    "    - They should be plausible, common misconceptions, or something a reader might easily confuse.\n",
    "    - They should not simply be direct negations of the text, nor should they be generally true statements that might confuse the student. \n",
    "    - You also need to give explanations for why each distractor is incorrect, but relevant to the question.\n",
    "\n",
    "Here's the information:\n",
    "\n",
    "Text Chunk: \"{text}\"\n",
    "\n",
    "Summary: \"{summary}\"\n",
    "\n",
    "Main Topic: \"{main_topic}\"\n",
    "\n",
    "Subtopic: \"{subtopics}\"\n",
    "\n",
    "The questions should be clear and give all the information needed, not requiring the reader to refer back to the context.\n",
    "The question MUST NOT containt the folowing or similar phrases:\n",
    "\"According to the text\", \"Based on the provided text\", \"According to the lecture slides\", \"as discussed\", \"as highlighted in the provided material\",\n",
    "\"In this lecture\", \"according to the provided information\", \"key focus of the discussion\"\n",
    "Instead, directly ask the questions. Do NOT specify which lecture, text, or source the question is based on. \n",
    "They don't know which text you are referring to, nor the context outside of the question.\n",
    "\n",
    "Your Output Should Be Formatted as Follows:\n",
    "\n",
    "Question: [Insert the multiple choice question here]\n",
    "\n",
    "A: [Answer Option A]\n",
    "\n",
    "B: [Answer Option B]\n",
    "\n",
    "C: [Answer Option C]\n",
    "\n",
    "D: [Answer Option D]\n",
    "\n",
    "Correct Answer: [The letter of the correct answer A, B, C, or D]\n",
    "\n",
    "A: [Explanation for this option]\n",
    "\n",
    "B: [Explanation for this option]\n",
    "\n",
    "C: [Explanation for this option]\n",
    "\n",
    "D: [Explanation for this option]\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parse the response from the LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': '[Insert the multiple choice question here]', 'correct_answer': '[Answer Option D]', 'correct_explanation': '[Explanation for Option D]', 'distractor1': '[Answer Option A]', 'distractor1_explanation': '[Explanation for Option A]', 'distractor2': '[Answer Option B]', 'distractor2_explanation': '[Explanation for Option B]', 'distractor3': '[Answer Option C]', 'distractor3_explanation': '[Explanation for Option C]'}\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This script parses a multiple-choice question from a given text input.\n",
    "It extracts the question, options, correct answer, and explanations,\n",
    "and organizes them into a structured dictionary format.\n",
    "\"\"\"\n",
    "\n",
    "def parse_question(text):\n",
    "    \"\"\"\n",
    "    Parses a multiple-choice question from a given text input.\n",
    "\n",
    "    Args:\n",
    "        text (str): The text containing the multiple-choice question.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing the question, options, correct answer,\n",
    "                distractors, and explanations.\n",
    "    \"\"\"\n",
    "\n",
    "    lines = [line.strip() for line in text.strip().split('\\n') if line.strip()]\n",
    "\n",
    "    if len(lines) < 10:\n",
    "        raise ValueError(\"Input text does not have the expected number of lines.\")\n",
    "    question = lines[0].replace('Question: ', '').strip()\n",
    "    options = {line[0]: line[3:].strip() for line in lines[1:5]}\n",
    "    explanations = {line[0]: line[3:].strip() for line in lines[6:10]}\n",
    "    correct_answer = lines[5].replace('Correct Answer: ', '').strip()\n",
    "    if correct_answer not in options:\n",
    "        raise ValueError(\"Correct answer key is not in the options.\")\n",
    "    # Create a list of distractors excluding the correct answer\n",
    "    distractors = [options[key] for key in options if key != correct_answer]\n",
    "\n",
    "    if len(distractors) < 3:\n",
    "        raise ValueError(\"Not enough distractors available.\")\n",
    "    question_data = {\n",
    "        'question': question,\n",
    "        'correct_answer': options[correct_answer],\n",
    "        'correct_explanation': explanations[correct_answer],\n",
    "        'distractor1': distractors[0],\n",
    "        'distractor1_explanation': explanations[[key for key in options \n",
    "                                                 if options[key] == distractors[0]][0]],\n",
    "        'distractor2': distractors[1],\n",
    "        'distractor2_explanation': explanations[[key for key in options \n",
    "                                                 if options[key] == distractors[1]][0]],\n",
    "        'distractor3': distractors[2],\n",
    "        'distractor3_explanation': explanations[[key for key in options \n",
    "                                                 if options[key] == distractors[2]][0]]\n",
    "    }\n",
    "\n",
    "    return question_data\n",
    "\n",
    "# Example usage\n",
    "TEXT = \"\"\"Question: [Insert the multiple choice question here]\n",
    "\n",
    "A: [Answer Option A]\n",
    "\n",
    "B: [Answer Option B]\n",
    "\n",
    "C: [Answer Option C]\n",
    "\n",
    "D: [Answer Option D]\n",
    "\n",
    "Correct Answer: D\n",
    "\n",
    "A: [Explanation for Option A]\n",
    "\n",
    "B: [Explanation for Option B]\n",
    "\n",
    "C: [Explanation for Option C]\n",
    "\n",
    "D: [Explanation for Option D]\n",
    "\"\"\"\n",
    "\n",
    "print(parse_question(TEXT))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:  The European Union employs mechanisms to address macroeconomic imbalances in member states.  One such mechanism, the Excessive Imbalance Procedure (EIP), is designed to ensure compliance with which broader procedure, and what potential consequence might a member state face for repeated failure to comply?\n",
      "\n",
      "A:  The Specific Monitoring procedure;  potential expulsion from the Eurozone.\n",
      "\n",
      "B:  The Macroeconomic Imbalance Procedure; potential sanctions, including fines.\n",
      "\n",
      "C:  The European Stability Mechanism; potential loss of access to financial assistance.\n",
      "\n",
      "D:  The Treaty Establishing the European Stability Mechanism;  potential legal action from the European Commission.\n",
      "\n",
      "\n",
      "Correct Answer: B\n",
      "\n",
      "A: This answer incorrectly identifies the Specific Monitoring procedure as the broader procedure, conflating two separate EU mechanisms for addressing macroeconomic issues. While Specific Monitoring is related, the EIP is directly designed to ensure compliance with the Macroeconomic Imbalance Procedure. Expulsion from the Eurozone is not a stated consequence of non-compliance with the EIP.\n",
      "\n",
      "B: This is the correct answer. The passage explicitly states that the EIP is \"designed to ensure compliance with the Macroeconomic Imbalance Procedure,\" and that repeated failure to comply can result in sanctions, including fines.\n",
      "\n",
      "C: The ESM is a separate mechanism providing financial assistance, not directly related to the enforcement of macroeconomic balance compliance.  While failure to comply with EIP might negatively impact a state's ability to receive ESM funds, this is not the direct consequence of the EIP itself.\n",
      "\n",
      "D: The Treaty establishing the ESM is a foundational document, not a procedure for addressing macroeconomic imbalances. Legal action is possible in the EU, but it's not the specific consequence outlined for non-compliance with the EIP.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = model.generate_content(PROMPT.format(text=text, summary=summary, main_topic=main_topic, subtopics=\", \".join(subtopics)))\n",
    "\"\"\"\n",
    "response2 = model.generate_content(\n",
    "            PROMPT.format(text=text, summary=summary, main_topic=main_topic, subtopics=\", \".join(subtopics)),\n",
    "            generation_config=genai.types.GenerationConfig(\n",
    "                candidate_count=1,\n",
    "                stop_sequences=None,\n",
    "                max_output_tokens=100,\n",
    "                temperature=0,\n",
    "            ),\n",
    "        )\n",
    "\"\"\"\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate one question from chunk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_question(chunk):\n",
    "    context = chunk['content']\n",
    "    \n",
    "    text = context.get('text', 'N/A')\n",
    "    summary = context.get('summary', 'N/A')\n",
    "    main_topic = context.get('main_topic', 'N/A')\n",
    "    subtopics = context.get('subtopics', 'N/A')\n",
    "\n",
    "    index = chunk['chunk_index']\n",
    "\n",
    "    response = model.generate_content(PROMPT.format(text=text, summary=summary, main_topic=main_topic, subtopics=\", \".join(subtopics)))\n",
    "    response_text = response.text\n",
    "\n",
    "    try:\n",
    "        question_data = parse_question(response_text)\n",
    "    except ValueError as e:\n",
    "        question_data = {'error': str(e)}\n",
    "    question_data['index'] = index\n",
    "\n",
    "    return question_data\n",
    "\n",
    "def save_to_json(data, file_name):\n",
    "    with open(file_name, 'w', encoding='utf-8') as f:\n",
    "        json.dump(data, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "# Example usage\n",
    "chunk = random_chunk\n",
    "question_data = generate_question(chunk)\n",
    "save_to_json(question_data, 'question_data.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Questions saved to 'all_questions.json' and 'all_questions.txt'\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Function to generate questions for all chunks\n",
    "def generate_questions_for_all_chunks(data):\n",
    "    all_questions = []\n",
    "    for chunk in data:\n",
    "        if chunk['type'] == 'chunk':\n",
    "            question_data = generate_question(chunk)\n",
    "            all_questions.append(question_data)\n",
    "    return all_questions\n",
    "\n",
    "# Generate questions for all chunks\n",
    "all_questions = generate_questions_for_all_chunks(data)\n",
    "\n",
    "# Save all questions to a JSON file\n",
    "with open('all_questions.json', 'w', encoding='utf-8') as json_file:\n",
    "    json.dump(all_questions, json_file, ensure_ascii=False, indent=4)\n",
    "\n",
    "# Print all questions to a text file in the format that the model returns\n",
    "with open('all_questions.txt', 'w', encoding='utf-8') as txt_file:\n",
    "    for question in all_questions:\n",
    "        if 'error' in question:\n",
    "            txt_file.write(f\"Error: {question['error']}\\n\\n\")\n",
    "            continue\n",
    "        # Create a list of answers\n",
    "        answers = [\n",
    "            question['distractor1'],\n",
    "            question['distractor2'],\n",
    "            question['distractor3'],\n",
    "            question['correct_answer']\n",
    "        ]\n",
    "        \n",
    "        # Shuffle the answers\n",
    "        random.shuffle(answers)\n",
    "        \n",
    "        # Write the question and answers to the file\n",
    "        txt_file.write(f\"Question: {question['question']}\\n\")\n",
    "        txt_file.write(f\"A: {answers[0]}\\n\")\n",
    "        txt_file.write(f\"B: {answers[1]}\\n\")\n",
    "        txt_file.write(f\"C: {answers[2]}\\n\")\n",
    "        txt_file.write(f\"D: {answers[3]}\\n\")\n",
    "        \n",
    "        # Find the new label for the correct answer\n",
    "        correct_label = 'ABCD'[answers.index(question['correct_answer'])]\n",
    "        txt_file.write(f\"Correct Answer: {correct_label}\\n\\n\")\n",
    "\n",
    "# Print the path of the generated files\n",
    "print(\"Questions saved to 'all_questions.json' and 'all_questions.txt'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate multiple questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Example usage\\nchunk = random_chunk\\nnum_questions = 8\\nquestions = generate_multiple_questions(chunk, num_questions)\\n\\nprint(questions)\\n\\n\\n\\nwith open(\\'multiple_questions.txt\\', \\'w\\', encoding=\\'utf-8\\') as txt_file:\\n    for question in questions:\\n        if \\'error\\' in question:\\n            txt_file.write(f\"Error: {question[\\'error\\']}\\n\\n\")\\n            continue\\n        # Create a list of answers\\n        answers = [\\n            question[\\'distractor1\\'],\\n            question[\\'distractor2\\'],\\n            question[\\'distractor3\\'],\\n            question[\\'correct_answer\\']\\n        ]\\n        \\n        # Shuffle the answers\\n        random.shuffle(answers)\\n        \\n        # Write the question and answers to the file\\n        txt_file.write(f\"Question: {question[\\'question\\']}\\n\")\\n        txt_file.write(f\"A: {answers[0]}\\n\")\\n        txt_file.write(f\"B: {answers[1]}\\n\")\\n        txt_file.write(f\"C: {answers[2]}\\n\")\\n        txt_file.write(f\"D: {answers[3]}\\n\")\\n        \\n        # Find the new label for the correct answer\\n        correct_label = \\'ABCD\\'[answers.index(question[\\'correct_answer\\'])]\\n        txt_file.write(f\"Correct Answer: {correct_label}\\n\\n\")\\n\\nprint(\"Multiple questions saved to \\'multiple_questions.txt\\'\")\\n'"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CHECK_IF_SIMILAR = \"\"\"\n",
    "Analyze if the answer options is contextually similar to a option from the answer set. \n",
    "Contextual similarity means that, while the wording may differ, the underlying meaning, concept, or information conveyed is essentially the same.\n",
    "If the answer set is empty, the answer isn't contextually similar to any other answer.\n",
    "\n",
    "Input:\n",
    "\n",
    "Answer Option: {answer_option}\n",
    "\n",
    "Answer Set: {answer_set}\n",
    "\n",
    "The output should be in the next format:\n",
    "\n",
    "Contextually Similar: [Yes/No]\n",
    "Explanation: [Explanation of why the answer is contextually similar or not]\n",
    "\"\"\" \n",
    "\n",
    "def generate_unique_question(chunk, existing_answers,yes_count, yes):\n",
    "    \"\"\"\n",
    "    Generates a unique question that is not contextually similar to existing answers.\n",
    "\n",
    "    Args:\n",
    "        chunk (dict): A dictionary containing information about the text chunk.\n",
    "        existing_answers (set): A set of existing answers to compare for similarity.\n",
    "        yes_count (int): The count of 'Yes' responses for contextual similarity.\n",
    "        yes (bool): A flag indicating if the question is contextually similar.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing the generated question data.\n",
    "        int: The updated count of 'Yes' responses for contextual similarity.\n",
    "        bool: A flag indicating if the question is contextually similar.\n",
    "    \"\"\"\n",
    "    while True:\n",
    "        question_data = generate_question(chunk)\n",
    "        # Error in the JSON dataset - skip this chunk\n",
    "        if 'error' in question_data:\n",
    "            yes_count = 3\n",
    "            yes = True\n",
    "            return question_data, yes_count, yes\n",
    "\n",
    "        response_answer = model.generate_content(CHECK_IF_SIMILAR.format(\n",
    "            answer_option=question_data['correct_answer'],\n",
    "            answer_set=\", \".join(existing_answers)))\n",
    "\n",
    "        if response_answer.text.startswith(\"Contextually Similar: Yes\"):\n",
    "            yes = True\n",
    "            yes_count += 1\n",
    "        return question_data, yes_count, yes\n",
    "        \n",
    "def generate_multiple_questions(chunk, num_questions = 5, minimum = 3, max_yes = 2):\n",
    "    \"\"\"\n",
    "    Generates multiple unique questions from a given data chunk.\n",
    "\n",
    "    Args:\n",
    "        chunk (dict): A dictionary containing information about the text chunk.\n",
    "        num_questions (int): The number of questions to generate.\n",
    "        minimum (int): The minimum number of questions to generate.\n",
    "        max_yes (int): The maximum number of 'Yes' responses for contextual similarity.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of dictionaries containing the generated question data.\n",
    "    \"\"\"\n",
    "    questions = []\n",
    "    existing_answers = set()\n",
    "    yes_count = 0\n",
    "    for i in range(num_questions):\n",
    "        yes = False\n",
    "        question_data, yes_count, yes = generate_unique_question(chunk,\n",
    "                                                                 existing_answers,\n",
    "                                                                 yes_count, yes)\n",
    "        if i >= minimum and yes_count >= max_yes:\n",
    "            return questions\n",
    "\n",
    "        if not yes:\n",
    "            questions.append(question_data)\n",
    "            existing_answers.add(question_data.get('correct_answer'))\n",
    "        else:\n",
    "            continue\n",
    "    return questions\n",
    "\n",
    "\"\"\"\n",
    "# Example usage\n",
    "chunk = random_chunk\n",
    "num_questions = 8\n",
    "questions = generate_multiple_questions(chunk, num_questions)\n",
    "\n",
    "print(questions)\n",
    "\n",
    "\n",
    "\n",
    "with open('multiple_questions.txt', 'w', encoding='utf-8') as txt_file:\n",
    "    for question in questions:\n",
    "        if 'error' in question:\n",
    "            txt_file.write(f\"Error: {question['error']}\\n\\n\")\n",
    "            continue\n",
    "        # Create a list of answers\n",
    "        answers = [\n",
    "            question['distractor1'],\n",
    "            question['distractor2'],\n",
    "            question['distractor3'],\n",
    "            question['correct_answer']\n",
    "        ]\n",
    "        \n",
    "        # Shuffle the answers\n",
    "        random.shuffle(answers)\n",
    "        \n",
    "        # Write the question and answers to the file\n",
    "        txt_file.write(f\"Question: {question['question']}\\n\")\n",
    "        txt_file.write(f\"A: {answers[0]}\\n\")\n",
    "        txt_file.write(f\"B: {answers[1]}\\n\")\n",
    "        txt_file.write(f\"C: {answers[2]}\\n\")\n",
    "        txt_file.write(f\"D: {answers[3]}\\n\")\n",
    "        \n",
    "        # Find the new label for the correct answer\n",
    "        correct_label = 'ABCD'[answers.index(question['correct_answer'])]\n",
    "        txt_file.write(f\"Correct Answer: {correct_label}\\n\\n\")\n",
    "\n",
    "print(\"Multiple questions saved to 'multiple_questions.txt'\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes count:  1\n",
      "Yes count:  2\n",
      "Yes count:  1\n",
      "Yes count:  2\n",
      "Yes count:  3\n",
      "Yes count:  1\n",
      "Yes count:  2\n",
      "Yes count:  3\n",
      "Yes count:  1\n",
      "Yes count:  2\n",
      "Yes count:  1\n",
      "Yes count:  1\n",
      "Yes count:  2\n",
      "Yes count:  3\n",
      "Yes count:  1\n",
      "Yes count:  1\n",
      "Yes count:  2\n",
      "Yes count:  1\n",
      "Yes count:  2\n",
      "Yes count:  1\n",
      "Yes count:  2\n",
      "Yes count:  1\n",
      "Yes count:  2\n",
      "Yes count:  1\n",
      "Yes count:  1\n",
      "Yes count:  2\n",
      "Questions saved to 'all_questions.json' and 'all_questions.txt'\n"
     ]
    }
   ],
   "source": [
    "import json, time\n",
    "\n",
    "# Function to generate questions for all chunks\n",
    "def generate_questions_for_all_chunks(data):\n",
    "    \"\"\"\n",
    "    Generates questions for all chunks in the provided data.\n",
    "\n",
    "    Args:\n",
    "        data (list): A list of dictionaries containing information about text chunks.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of dictionaries containing the generated question data for each chunk.\n",
    "    \"\"\"\n",
    "    all_questions = []\n",
    "    for chunk in data:\n",
    "        if chunk['type'] == 'chunk':\n",
    "            question_data = generate_multiple_questions(chunk)\n",
    "            # Sleep for 1 minute to avoid rate limiting - adjustment in the documentation\n",
    "            time.sleep(60)\n",
    "            all_questions.append(question_data)\n",
    "    return all_questions\n",
    "\n",
    "# Generate questions for all chunks\n",
    "all_questions = generate_questions_for_all_chunks(data)\n",
    "\n",
    "# Save all questions to a JSON file\n",
    "with open('all_questions.json', 'w', encoding='utf-8') as json_file:\n",
    "    json.dump(all_questions, json_file, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(\"Questions saved to 'all_questions.json'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "\n",
    "def generate_questions_for_all_chunks(data):\n",
    "    \"\"\"\n",
    "    Generates questions for all chunks in the provided data.\n",
    "\n",
    "    Args:\n",
    "        data (list): A list of dictionaries containing information about text chunks.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of dictionaries containing the generated question data for each chunk.\n",
    "    \"\"\"\n",
    "    all_questions = []\n",
    "    for chunk in data:\n",
    "        if chunk['type'] == 'chunk':\n",
    "            question_data = generate_multiple_questions(chunk)\n",
    "            # Sleep for 1 minute to avoid rate limiting - adjustment in the documentation\n",
    "            time.sleep(60)\n",
    "            all_questions.append(question_data)\n",
    "    return all_questions\n",
    "\n",
    "def save_questions_to_file(input_json, output_txt):\n",
    "    \"\"\"\n",
    "    Saves questions from a JSON file to a text file in a specific format.\n",
    "\n",
    "    Args:\n",
    "        input_json (str): The path to the JSON file containing the questions.\n",
    "        output_txt (str): The path to the text file to save the questions to.\n",
    "    \"\"\"\n",
    "\n",
    "    with open(input_json, 'r', encoding='utf-8') as json_file:\n",
    "        all_questions = json.load(json_file)\n",
    "\n",
    "    with open(output_txt, 'w', encoding='utf-8') as txt_file:\n",
    "        for _, questions in enumerate(all_questions):\n",
    "            try:\n",
    "                for i, question in enumerate(questions):\n",
    "                    # Create a list of answers\n",
    "                    answers = [\n",
    "                        question['distractor1'],\n",
    "                        question['distractor2'],\n",
    "                        question['distractor3'],\n",
    "                        question['correct_answer']\n",
    "                        ]\n",
    "                    # Shuffle the answers\n",
    "                    random.shuffle(answers)\n",
    "                    # Write the question and answers to the file\n",
    "                    txt_file.write(f\"Question n. {question['index']}.{i}: {question['question']}\\n\")\n",
    "                    txt_file.write(f\"A: {answers[0]}\\n\")\n",
    "                    txt_file.write(f\"B: {answers[1]}\\n\")\n",
    "                    txt_file.write(f\"C: {answers[2]}\\n\")\n",
    "                    txt_file.write(f\"D: {answers[3]}\\n\")\n",
    "                    # Find the new label for the correct answer\n",
    "                    correct_label = 'ABCD'[answers.index(question['correct_answer'])]\n",
    "                    txt_file.write(f\"Correct Answer: {correct_label}\\n\\n\")\n",
    "            except KeyError as e:\n",
    "                print(f\"KeyError: Missing key {e} in question {question}\")\n",
    "            except IndexError as e:\n",
    "                print(f\"IndexError: {e} in question {question}\")\n",
    "            except TypeError as e:\n",
    "                print(f\"TypeError: {e} in question {question}\")\n",
    "            except ValueError as e:\n",
    "                print(f\"ValueError: {e} in question {question}\")\n",
    "\n",
    "# Example usage\n",
    "save_questions_to_file('all_questions_multiple.json', 'all_questions.txt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
